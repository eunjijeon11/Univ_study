{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8366848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:56:10.845809Z",
     "start_time": "2022-12-08T02:56:09.447762Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e6311",
   "metadata": {},
   "source": [
    "## pytorch 기초\n",
    "- 텐서 만들기\n",
    "- 텐서 계산\n",
    "- reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f06fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:01:50.205964Z",
     "start_time": "2022-11-30T05:01:50.185416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([[0.0000, 1.8750, 0.0000],\n",
      "        [1.8750, 0.0000, 1.8750]])\n",
      "tensor([[0.4660, 0.6340],\n",
      "        [0.6902, 0.8038]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.float32\n",
      "torch.float64\n",
      "torch.Size([2, 2])\n",
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(1) # scalar\n",
    "print(x)\n",
    "\n",
    "x = torch.empty(2, 3)\n",
    "print(x)\n",
    "\n",
    "x = torch.rand(2, 2) # random value\n",
    "print(x)\n",
    "\n",
    "x = torch.zeros(2, 2) # 0 행렬\n",
    "print(x)\n",
    "\n",
    "x = torch.ones(2, 2)\n",
    "print(x)\n",
    "\n",
    "print(x.dtype)\n",
    "\n",
    "x = torch.ones(2, 2, dtype=torch.double)\n",
    "print(x.dtype)\n",
    "\n",
    "print(x.size()) # size\n",
    "\n",
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cba95b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:02:15.462570Z",
     "start_time": "2022-11-30T05:02:15.451574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3574, 0.3255],\n",
      "        [0.8211, 0.5588]]) tensor([[0.2632, 0.0494],\n",
      "        [0.7208, 0.8840]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "print(x, y)\n",
    "\n",
    "z = x + y # element-wise addition\n",
    "z = torch.add(x, y)\n",
    "\n",
    "y.add_(x) # replace y\n",
    "\n",
    "z = x - y\n",
    "z = torch.sub(x, y)\n",
    "\n",
    "z = x * y\n",
    "z = torch.mul(x, y)\n",
    "z = torch.div(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e8206b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:22:21.501461Z",
     "start_time": "2022-11-30T05:22:21.486216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2284, 0.1543, 0.6603],\n",
      "        [0.8776, 0.6959, 0.7093],\n",
      "        [0.7571, 0.2065, 0.4137],\n",
      "        [0.3234, 0.5165, 0.3466],\n",
      "        [0.2644, 0.0262, 0.1286]])\n",
      "tensor([0.2284, 0.8776, 0.7571, 0.3234, 0.2644])\n",
      "tensor([0.2284, 0.1543, 0.6603])\n",
      "0.6958613395690918\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x[:, 0])\n",
    "print(x[0, :])\n",
    "print(x[1, 1].item()) # get actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beee2974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:23:49.824959Z",
     "start_time": "2022-11-30T05:23:49.815871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2425, 0.7683, 0.1925, 0.9926],\n",
      "        [0.5365, 0.2960, 0.6009, 0.6667],\n",
      "        [0.6705, 0.5172, 0.8612, 0.8960],\n",
      "        [0.1927, 0.8660, 0.1145, 0.0247]])\n",
      "tensor([0.2425, 0.7683, 0.1925, 0.9926, 0.5365, 0.2960, 0.6009, 0.6667, 0.6705,\n",
      "        0.5172, 0.8612, 0.8960, 0.1927, 0.8660, 0.1145, 0.0247])\n",
      "tensor([[0.2425, 0.7683, 0.1925, 0.9926, 0.5365, 0.2960, 0.6009, 0.6667],\n",
      "        [0.6705, 0.5172, 0.8612, 0.8960, 0.1927, 0.8660, 0.1145, 0.0247]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "\n",
    "y = x.view(16) # reshape\n",
    "z = x.view(-1, 8) # 2 * 8\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6f489c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:56:13.956253Z",
     "start_time": "2022-12-08T02:56:13.934228Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()  # pointer\n",
    "print(type(b))\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b) ###\n",
    "\n",
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248944bf",
   "metadata": {},
   "source": [
    "## gradient 추적\n",
    "- grad_fn\n",
    "- backward()\n",
    "- grad.zero()의 필요성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fc1c54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:48:20.386873Z",
     "start_time": "2022-11-30T05:48:20.375623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7570,  1.4063,  1.5096], requires_grad=True)\n",
      "tensor([1.2430, 3.4063, 3.5096], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.0900, 23.2057, 24.6343], grad_fn=<MulBackward0>)\n",
      "tensor([ 0.4972, 13.6252,  0.0140])\n"
     ]
    }
   ],
   "source": [
    "# autograd\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y) # grad_fn=<AddBackward0>\n",
    "\n",
    "z = y * y * 2\n",
    "print(z) # grad_fn=<MulBackward0>\n",
    "\n",
    "#z = z.mean()\n",
    "#print(z) # grad_fn=<MeanBackward0>\n",
    "\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v)  # Jacobian matrix\n",
    "print(x.grad) # grad is for scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53d6881b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:53:10.689809Z",
     "start_time": "2022-11-30T05:53:10.672660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2328, 2.3579, 2.6878])\n",
      "tensor([2.2328, 2.3579, 2.6878])\n"
     ]
    }
   ],
   "source": [
    "# tracking stop\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "# x.requires_grad_(False)\n",
    "# x.detach()\n",
    "# with torch.no_grad()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e8af03b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T06:55:56.229708Z",
     "start_time": "2022-11-30T06:55:56.213373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad = True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum()\n",
    "    \n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01674df2",
   "metadata": {},
   "source": [
    "## 모듈, 레이어, 함수 사용\n",
    "- linear regression with calculation\n",
    "- linear regression using torch module\n",
    "- layers\n",
    "    - softmax\n",
    "- loss functions\n",
    "    - cross entropy loss\n",
    "- activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b94619f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T07:14:31.024963Z",
     "start_time": "2022-11-30T07:14:31.007579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad = True)\n",
    "\n",
    "# forward pass and compute loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y) ** 2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "### update weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d5eea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:56:19.852800Z",
     "start_time": "2022-12-08T02:56:19.819991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 2.5565314292907715 loss 16.15556335\n",
      "epoch 2 w 1.0997847318649292 loss 7.33158398\n",
      "epoch 3 w 2.0916807651519775 loss 3.36517286\n",
      "epoch 4 w 1.4423644542694092 loss 1.57999539\n",
      "epoch 5 w 1.8923017978668213 loss 0.77440822\n",
      "epoch 6 w 1.6052273511886597 loss 0.40888008\n",
      "epoch 7 w 1.811564564704895 loss 0.24115576\n",
      "epoch 8 w 1.6868669986724854 loss 0.16245469\n",
      "epoch 9 w 1.7835770845413208 loss 0.12392347\n",
      "epoch 10 w 1.7315367460250854 loss 0.10361658\n",
      "epoch 11 w 1.778786063194275 loss 0.09166928\n",
      "epoch 12 w 1.7591347694396973 loss 0.08364240\n",
      "epoch 13 w 1.7839512825012207 loss 0.07753260\n",
      "epoch 14 w 1.778623104095459 loss 0.07243142\n",
      "epoch 15 w 1.7931551933288574 loss 0.06792218\n",
      "epoch 16 w 1.7940516471862793 loss 0.06380952\n",
      "epoch 17 w 1.8037662506103516 loss 0.05999812\n",
      "epoch 18 w 1.8072636127471924 loss 0.05643790\n",
      "epoch 19 w 1.8146270513534546 loss 0.05309944\n",
      "epoch 20 w 1.8191094398498535 loss 0.04996326\n",
      "epoch 21 w 1.8252403736114502 loss 0.04701439\n",
      "epoch 22 w 1.8299933671951294 loss 0.04424053\n",
      "epoch 23 w 1.8354041576385498 loss 0.04163073\n",
      "epoch 24 w 1.84011709690094 loss 0.03917511\n",
      "epoch 25 w 1.8450477123260498 loss 0.03686440\n",
      "epoch 26 w 1.8495904207229614 loss 0.03469006\n",
      "epoch 27 w 1.8541581630706787 loss 0.03264394\n",
      "epoch 28 w 1.8584812879562378 loss 0.03071857\n",
      "epoch 29 w 1.862747073173523 loss 0.02890668\n",
      "epoch 30 w 1.8668370246887207 loss 0.02720176\n",
      "epoch 31 w 1.8708367347717285 loss 0.02559733\n",
      "epoch 32 w 1.874695062637329 loss 0.02408756\n",
      "epoch 33 w 1.8784524202346802 loss 0.02266683\n",
      "epoch 34 w 1.8820874691009521 loss 0.02132990\n",
      "epoch 35 w 1.8856202363967896 loss 0.02007183\n",
      "epoch 36 w 1.8890429735183716 loss 0.01888799\n",
      "epoch 37 w 1.8923660516738892 loss 0.01777394\n",
      "epoch 38 w 1.8955878019332886 loss 0.01672559\n",
      "epoch 39 w 1.898714303970337 loss 0.01573908\n",
      "epoch 40 w 1.901746392250061 loss 0.01481077\n",
      "epoch 41 w 1.9046881198883057 loss 0.01393719\n",
      "epoch 42 w 1.9075416326522827 loss 0.01311515\n",
      "epoch 43 w 1.9103097915649414 loss 0.01234161\n",
      "epoch 44 w 1.9129948616027832 loss 0.01161367\n",
      "epoch 45 w 1.9155999422073364 loss 0.01092868\n",
      "epoch 46 w 1.9181265830993652 loss 0.01028408\n",
      "epoch 47 w 1.9205780029296875 loss 0.00967751\n",
      "epoch 48 w 1.9229557514190674 loss 0.00910672\n",
      "epoch 49 w 1.9252623319625854 loss 0.00856959\n",
      "epoch 50 w 1.9275000095367432 loss 0.00806414\n",
      "prediction after training: f(5) = 9.850658\n"
     ]
    }
   ],
   "source": [
    "# design model (input, output size, forward pass)\n",
    "# construct loss and optimizer\n",
    "# training loop\n",
    "#   - forward pass: compute prediction\n",
    "#   - backward pass: gradients\n",
    "#   - update weights\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_test = torch.tensor([[5]], dtype=torch.float32)\n",
    "input_size = n_features  # 1\n",
    "output_size = n_features  # 1\n",
    "#model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "# training\n",
    "lr = 0.1\n",
    "n_iters = 50\n",
    "\n",
    "# loss (MSE)\n",
    "loss = nn.MSELoss()  # callable function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # backward pass\n",
    "    l.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    [w, b] = model.parameters()\n",
    "    print(\"epoch\", epoch+1, \"w\", w[0][0].item(), f\"loss {l:.8f}\")\n",
    "\n",
    "print(f\"prediction after training: f(5) = {model(X_test).item():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bd34e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T15:22:39.119910Z",
     "start_time": "2022-11-30T15:22:39.093638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80ffb2d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T15:31:47.734913Z",
     "start_time": "2022-11-30T15:31:47.701530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4170299470424652\n",
      "1.840616226196289\n",
      "tensor([0])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# nn.CrossEntropyLoss\n",
    "#   - applies softmax and negative log likelihood loss\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([0])\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item()) # bigger\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good, 1) # class number, 1=dim\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e97c6cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T03:45:23.257480Z",
     "start_time": "2022-12-08T03:45:23.234685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3018244206905365\n",
      "1.6241613626480103\n",
      "tensor([2, 0, 1])\n",
      "tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item()) # bigger\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good, 1) # class number, 1=dim\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58858275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T08:58:50.343230Z",
     "start_time": "2022-12-01T08:58:50.320980Z"
    }
   },
   "outputs": [],
   "source": [
    "# activation functions\n",
    "#   - tanh, ReLU, leaky ReLU...\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(x))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3b799",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30faf506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:57:07.769468Z",
     "start_time": "2022-12-08T02:57:06.584418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "#for i in range(6):\n",
    "    #plt.subplot(2, 3, i+1)\n",
    "    #plt.imshow(samples[i][0], cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be60df54",
   "metadata": {},
   "source": [
    "## training example\n",
    "- feed forward\n",
    "- CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd94ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:56:57.274069Z",
     "start_time": "2022-12-01T13:56:57.261205Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)  # softmax will be in loss func\n",
    "    \n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f52f763b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:57:17.409995Z",
     "start_time": "2022-12-01T13:56:57.631997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 2, step 100 / 600, loss=0.4377399682998657\n",
      "epoch 1 / 2, step 200 / 600, loss=0.21925944089889526\n",
      "epoch 1 / 2, step 300 / 600, loss=0.3644927144050598\n",
      "epoch 1 / 2, step 400 / 600, loss=0.259533166885376\n",
      "epoch 1 / 2, step 500 / 600, loss=0.3550701141357422\n",
      "epoch 1 / 2, step 600 / 600, loss=0.1980101764202118\n",
      "epoch 2 / 2, step 100 / 600, loss=0.13710418343544006\n",
      "epoch 2 / 2, step 200 / 600, loss=0.11186003684997559\n",
      "epoch 2 / 2, step 300 / 600, loss=0.10720031708478928\n",
      "epoch 2 / 2, step 400 / 600, loss=0.1499468982219696\n",
      "epoch 2 / 2, step 500 / 600, loss=0.30395081639289856\n",
      "epoch 2 / 2, step 600 / 600, loss=0.06162792816758156\n",
      "accuracy = 95.57833333333333\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"epoch {epoch + 1} / {num_epochs}, step {i+1} / {n_total_steps}, loss={loss.item()}\")\n",
    "            \n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value & index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f\"accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00702f1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T19:13:52.959475Z",
     "start_time": "2022-12-01T19:11:35.940171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "epoch [1/4], step [2000/12500], loss: 2.304253101348877\n",
      "epoch [1/4], step [4000/12500], loss: 2.283416271209717\n",
      "epoch [1/4], step [6000/12500], loss: 2.3116536140441895\n",
      "epoch [1/4], step [8000/12500], loss: 2.3332762718200684\n",
      "epoch [1/4], step [10000/12500], loss: 2.235795497894287\n",
      "epoch [1/4], step [12000/12500], loss: 2.2670185565948486\n",
      "epoch [2/4], step [2000/12500], loss: 1.9421439170837402\n",
      "epoch [2/4], step [4000/12500], loss: 1.843127727508545\n",
      "epoch [2/4], step [6000/12500], loss: 2.53489351272583\n",
      "epoch [2/4], step [8000/12500], loss: 1.8630787134170532\n",
      "epoch [2/4], step [10000/12500], loss: 1.503590703010559\n",
      "epoch [2/4], step [12000/12500], loss: 1.8765625953674316\n",
      "epoch [3/4], step [2000/12500], loss: 1.0686606168746948\n",
      "epoch [3/4], step [4000/12500], loss: 1.6661685705184937\n",
      "epoch [3/4], step [6000/12500], loss: 1.9689804315567017\n",
      "epoch [3/4], step [8000/12500], loss: 1.7867835760116577\n",
      "epoch [3/4], step [10000/12500], loss: 2.406804084777832\n",
      "epoch [3/4], step [12000/12500], loss: 1.452519416809082\n",
      "epoch [4/4], step [2000/12500], loss: 1.0834487676620483\n",
      "epoch [4/4], step [4000/12500], loss: 2.338414192199707\n",
      "epoch [4/4], step [6000/12500], loss: 1.2446844577789307\n",
      "epoch [4/4], step [8000/12500], loss: 1.5431127548217773\n",
      "epoch [4/4], step [10000/12500], loss: 1.0550730228424072\n",
      "epoch [4/4], step [12000/12500], loss: 2.8469319343566895\n",
      "training finised\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                            download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                            transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\",\n",
    "          \"ship\", \"truck\")\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5) #flatten\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2000 == 0:\n",
    "            print(f\"epoch [{epoch+1}/{num_epochs}], step [{i+1}/{n_total_steps}], loss: {loss.item()}\")\n",
    "\n",
    "print(\"training finised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd286db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T19:14:22.345659Z",
     "start_time": "2022-12-01T19:14:01.784706Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 46.51 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f\"Accuracy of the network: {acc} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb413e74",
   "metadata": {},
   "source": [
    "## dataset transforms\n",
    "- data = dataiter.next() -> data = next(dataiter)\n",
    "- batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4a2690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T03:19:06.367511Z",
     "start_time": "2022-12-08T03:19:06.341448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# dataset transforms\n",
    "# Batches\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('./data/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # array([[1], [2], [3], ...])\n",
    "        self.n_samples = xy.shape[0] # first dimension\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e80346dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T03:21:37.541236Z",
     "start_time": "2022-12-08T03:21:37.528033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3160e+01, 2.3600e+00, 2.6700e+00, 1.8600e+01, 1.0100e+02, 2.8000e+00,\n",
      "         3.2400e+00, 3.0000e-01, 2.8100e+00, 5.6800e+00, 1.0300e+00, 3.1700e+00,\n",
      "         1.1850e+03],\n",
      "        [1.2370e+01, 1.2100e+00, 2.5600e+00, 1.8100e+01, 9.8000e+01, 2.4200e+00,\n",
      "         2.6500e+00, 3.7000e-01, 2.0800e+00, 4.6000e+00, 1.1900e+00, 2.3000e+00,\n",
      "         6.7800e+02],\n",
      "        [1.3730e+01, 1.5000e+00, 2.7000e+00, 2.2500e+01, 1.0100e+02, 3.0000e+00,\n",
      "         3.2500e+00, 2.9000e-01, 2.3800e+00, 5.7000e+00, 1.1900e+00, 2.7100e+00,\n",
      "         1.2850e+03],\n",
      "        [1.3580e+01, 2.5800e+00, 2.6900e+00, 2.4500e+01, 1.0500e+02, 1.5500e+00,\n",
      "         8.4000e-01, 3.9000e-01, 1.5400e+00, 8.6600e+00, 7.4000e-01, 1.8000e+00,\n",
      "         7.5000e+02]]) tensor([[1.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# iterator\n",
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfff1d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T03:23:08.499509Z",
     "start_time": "2022-12-08T03:23:08.484788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples / 4)\n",
    "print(total_samples, n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211b84e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T03:25:51.572432Z",
     "start_time": "2022-12-08T03:25:51.543998Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        #forward\n",
    "        \n",
    "        #backward\n",
    "        \n",
    "        #update\n",
    "        \n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"epoch {epoch+1}/{epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning (transfer learning)\n",
    "# scheduler\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicoding",
   "language": "python",
   "name": "aicoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
