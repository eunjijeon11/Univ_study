{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8366848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:13:12.217246Z",
     "start_time": "2022-12-01T10:13:10.909874Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f06fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:01:50.205964Z",
     "start_time": "2022-11-30T05:01:50.185416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([[0.0000, 1.8750, 0.0000],\n",
      "        [1.8750, 0.0000, 1.8750]])\n",
      "tensor([[0.4660, 0.6340],\n",
      "        [0.6902, 0.8038]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.float32\n",
      "torch.float64\n",
      "torch.Size([2, 2])\n",
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(1) # scalar\n",
    "print(x)\n",
    "\n",
    "x = torch.empty(2, 3)\n",
    "print(x)\n",
    "\n",
    "x = torch.rand(2, 2) # random value\n",
    "print(x)\n",
    "\n",
    "x = torch.zeros(2, 2) # 0 행렬\n",
    "print(x)\n",
    "\n",
    "x = torch.ones(2, 2)\n",
    "print(x)\n",
    "\n",
    "print(x.dtype)\n",
    "\n",
    "x = torch.ones(2, 2, dtype=torch.double)\n",
    "print(x.dtype)\n",
    "\n",
    "print(x.size()) # size\n",
    "\n",
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cba95b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:02:15.462570Z",
     "start_time": "2022-11-30T05:02:15.451574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3574, 0.3255],\n",
      "        [0.8211, 0.5588]]) tensor([[0.2632, 0.0494],\n",
      "        [0.7208, 0.8840]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "print(x, y)\n",
    "\n",
    "z = x + y # element-wise addition\n",
    "z = torch.add(x, y)\n",
    "\n",
    "y.add_(x) # replace y\n",
    "\n",
    "z = x - y\n",
    "z = torch.sub(x, y)\n",
    "\n",
    "z = x * y\n",
    "z = torch.mul(x, y)\n",
    "z = torch.div(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e8206b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:22:21.501461Z",
     "start_time": "2022-11-30T05:22:21.486216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2284, 0.1543, 0.6603],\n",
      "        [0.8776, 0.6959, 0.7093],\n",
      "        [0.7571, 0.2065, 0.4137],\n",
      "        [0.3234, 0.5165, 0.3466],\n",
      "        [0.2644, 0.0262, 0.1286]])\n",
      "tensor([0.2284, 0.8776, 0.7571, 0.3234, 0.2644])\n",
      "tensor([0.2284, 0.1543, 0.6603])\n",
      "0.6958613395690918\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x[:, 0])\n",
    "print(x[0, :])\n",
    "print(x[1, 1].item()) # get actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beee2974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:23:49.824959Z",
     "start_time": "2022-11-30T05:23:49.815871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2425, 0.7683, 0.1925, 0.9926],\n",
      "        [0.5365, 0.2960, 0.6009, 0.6667],\n",
      "        [0.6705, 0.5172, 0.8612, 0.8960],\n",
      "        [0.1927, 0.8660, 0.1145, 0.0247]])\n",
      "tensor([0.2425, 0.7683, 0.1925, 0.9926, 0.5365, 0.2960, 0.6009, 0.6667, 0.6705,\n",
      "        0.5172, 0.8612, 0.8960, 0.1927, 0.8660, 0.1145, 0.0247])\n",
      "tensor([[0.2425, 0.7683, 0.1925, 0.9926, 0.5365, 0.2960, 0.6009, 0.6667],\n",
      "        [0.6705, 0.5172, 0.8612, 0.8960, 0.1927, 0.8660, 0.1145, 0.0247]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "\n",
    "y = x.view(16) # reshape\n",
    "z = x.view(-1, 8) # 2 * 8\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6f489c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:13:14.966171Z",
     "start_time": "2022-12-01T10:13:14.938304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()  # pointer\n",
    "print(type(b))\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b) ###\n",
    "\n",
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fc1c54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:48:20.386873Z",
     "start_time": "2022-11-30T05:48:20.375623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7570,  1.4063,  1.5096], requires_grad=True)\n",
      "tensor([1.2430, 3.4063, 3.5096], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.0900, 23.2057, 24.6343], grad_fn=<MulBackward0>)\n",
      "tensor([ 0.4972, 13.6252,  0.0140])\n"
     ]
    }
   ],
   "source": [
    "# autograd\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y) # grad_fn=<AddBackward0>\n",
    "\n",
    "z = y * y * 2\n",
    "print(z) # grad_fn=<MulBackward0>\n",
    "\n",
    "#z = z.mean()\n",
    "#print(z) # grad_fn=<MeanBackward0>\n",
    "\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v)  # Jacobian matrix\n",
    "print(x.grad) # grad is for scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53d6881b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T05:53:10.689809Z",
     "start_time": "2022-11-30T05:53:10.672660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2328, 2.3579, 2.6878])\n",
      "tensor([2.2328, 2.3579, 2.6878])\n"
     ]
    }
   ],
   "source": [
    "# tracking stop\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "# x.requires_grad_(False)\n",
    "# x.detach()\n",
    "# with torch.no_grad()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e8af03b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T06:55:56.229708Z",
     "start_time": "2022-11-30T06:55:56.213373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad = True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum()\n",
    "    \n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b94619f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T07:14:31.024963Z",
     "start_time": "2022-11-30T07:14:31.007579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad = True)\n",
    "\n",
    "# forward pass and compute loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y) ** 2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "### update weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d5eea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:13:21.954236Z",
     "start_time": "2022-12-01T10:13:21.930966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 2.478407382965088 loss 14.74305916\n",
      "epoch 2 w 1.0908863544464111 loss 6.71656799\n",
      "epoch 3 w 2.0382308959960938 loss 3.10708952\n",
      "epoch 4 w 1.4205451011657715 loss 1.48110580\n",
      "epoch 5 w 1.8510136604309082 loss 0.74599046\n",
      "epoch 6 w 1.5786584615707397 loss 0.41115931\n",
      "epoch 7 w 1.7767564058303833 loss 0.25633037\n",
      "epoch 8 w 1.659155011177063 loss 0.18258454\n",
      "epoch 9 w 1.7526381015777588 loss 0.14549276\n",
      "epoch 10 w 1.7042421102523804 loss 0.12509315\n",
      "epoch 11 w 1.7504874467849731 loss 0.11240874\n",
      "epoch 12 w 1.7329035997390747 loss 0.10339635\n",
      "epoch 13 w 1.7576879262924194 loss 0.09622820\n",
      "epoch 14 w 1.7536938190460205 loss 0.09007213\n",
      "epoch 15 w 1.76860511302948 loss 0.08454388\n",
      "epoch 16 w 1.7704826593399048 loss 0.07946055\n",
      "epoch 17 w 1.780738115310669 loss 0.07473037\n",
      "epoch 18 w 1.7850350141525269 loss 0.07030312\n",
      "epoch 19 w 1.7929904460906982 loss 0.06614782\n",
      "epoch 20 w 1.798169732093811 loss 0.06224236\n",
      "epoch 21 w 1.8048948049545288 loss 0.05856947\n",
      "epoch 22 w 1.8102787733078003 loss 0.05511410\n",
      "epoch 23 w 1.8162652254104614 loss 0.05186303\n",
      "epoch 24 w 1.8215607404708862 loss 0.04880396\n",
      "epoch 25 w 1.827040672302246 loss 0.04592532\n",
      "epoch 26 w 1.8321266174316406 loss 0.04321654\n",
      "epoch 27 w 1.837214469909668 loss 0.04066752\n",
      "epoch 28 w 1.8420467376708984 loss 0.03826889\n",
      "epoch 29 w 1.8468034267425537 loss 0.03601172\n",
      "epoch 30 w 1.85137140750885 loss 0.03388769\n",
      "epoch 31 w 1.8558335304260254 loss 0.03188891\n",
      "epoch 32 w 1.8601415157318115 loss 0.03000806\n",
      "epoch 33 w 1.864334225654602 loss 0.02823814\n",
      "epoch 34 w 1.8683922290802002 loss 0.02657259\n",
      "epoch 35 w 1.8723348379135132 loss 0.02500527\n",
      "epoch 36 w 1.8761554956436157 loss 0.02353044\n",
      "epoch 37 w 1.8798643350601196 loss 0.02214259\n",
      "epoch 38 w 1.883460283279419 loss 0.02083660\n",
      "epoch 39 w 1.886949896812439 loss 0.01960758\n",
      "epoch 40 w 1.8903342485427856 loss 0.01845109\n",
      "epoch 41 w 1.8936176300048828 loss 0.01736283\n",
      "epoch 42 w 1.8968026638031006 loss 0.01633873\n",
      "epoch 43 w 1.8998922109603882 loss 0.01537505\n",
      "epoch 44 w 1.902889370918274 loss 0.01446820\n",
      "epoch 45 w 1.905796766281128 loss 0.01361483\n",
      "epoch 46 w 1.9086171388626099 loss 0.01281182\n",
      "epoch 47 w 1.9113529920578003 loss 0.01205617\n",
      "epoch 48 w 1.9140070676803589 loss 0.01134505\n",
      "epoch 49 w 1.9165815114974976 loss 0.01067591\n",
      "epoch 50 w 1.919079065322876 loss 0.01004624\n",
      "prediction after training: f(5) = 9.833313\n"
     ]
    }
   ],
   "source": [
    "# design model (input, output size, forward pass)\n",
    "# construct loss and optimizer\n",
    "# training loop\n",
    "#   - forward pass: compute prediction\n",
    "#   - backward pass: gradients\n",
    "#   - update weights\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_test = torch.tensor([[5]], dtype=torch.float32)\n",
    "input_size = n_features  # 1\n",
    "output_size = n_features  # 1\n",
    "#model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "# training\n",
    "lr = 0.1\n",
    "n_iters = 50\n",
    "\n",
    "# loss (MSE)\n",
    "loss = nn.MSELoss()  # callable function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # backward pass\n",
    "    l.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    [w, b] = model.parameters()\n",
    "    print(\"epoch\", epoch+1, \"w\", w[0][0].item(), f\"loss {l:.8f}\")\n",
    "\n",
    "print(f\"prediction after training: f(5) = {model(X_test).item():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bd34e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T15:22:39.119910Z",
     "start_time": "2022-11-30T15:22:39.093638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80ffb2d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T15:31:47.734913Z",
     "start_time": "2022-11-30T15:31:47.701530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4170299470424652\n",
      "1.840616226196289\n",
      "tensor([0])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# nn.CrossEntropyLoss\n",
    "#   - applies softmax and negative log likelihood loss\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([0])\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item()) # bigger\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good, 1) # class number, 1=dim\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e97c6cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T15:35:28.432575Z",
     "start_time": "2022-11-30T15:35:28.406921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3018244206905365\n",
      "1.6241613626480103\n",
      "tensor([2, 0, 1])\n",
      "tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item()) # bigger\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good, 1) # class number, 1=dim\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58858275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T08:58:50.343230Z",
     "start_time": "2022-12-01T08:58:50.320980Z"
    }
   },
   "outputs": [],
   "source": [
    "# activation functions\n",
    "#   - tanh, ReLU, leaky ReLU...\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(x))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30faf506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T10:14:16.931419Z",
     "start_time": "2022-12-01T10:14:16.442270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd94ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:56:57.274069Z",
     "start_time": "2022-12-01T13:56:57.261205Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)  # softmax will be in loss func\n",
    "    \n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f52f763b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:57:17.409995Z",
     "start_time": "2022-12-01T13:56:57.631997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 2, step 100 / 600, loss=0.4377399682998657\n",
      "epoch 1 / 2, step 200 / 600, loss=0.21925944089889526\n",
      "epoch 1 / 2, step 300 / 600, loss=0.3644927144050598\n",
      "epoch 1 / 2, step 400 / 600, loss=0.259533166885376\n",
      "epoch 1 / 2, step 500 / 600, loss=0.3550701141357422\n",
      "epoch 1 / 2, step 600 / 600, loss=0.1980101764202118\n",
      "epoch 2 / 2, step 100 / 600, loss=0.13710418343544006\n",
      "epoch 2 / 2, step 200 / 600, loss=0.11186003684997559\n",
      "epoch 2 / 2, step 300 / 600, loss=0.10720031708478928\n",
      "epoch 2 / 2, step 400 / 600, loss=0.1499468982219696\n",
      "epoch 2 / 2, step 500 / 600, loss=0.30395081639289856\n",
      "epoch 2 / 2, step 600 / 600, loss=0.06162792816758156\n",
      "accuracy = 95.57833333333333\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"epoch {epoch + 1} / {num_epochs}, step {i+1} / {n_total_steps}, loss={loss.item()}\")\n",
    "            \n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value & index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f\"accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00702f1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T19:13:52.959475Z",
     "start_time": "2022-12-01T19:11:35.940171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "epoch [1/4], step [2000/12500], loss: 2.304253101348877\n",
      "epoch [1/4], step [4000/12500], loss: 2.283416271209717\n",
      "epoch [1/4], step [6000/12500], loss: 2.3116536140441895\n",
      "epoch [1/4], step [8000/12500], loss: 2.3332762718200684\n",
      "epoch [1/4], step [10000/12500], loss: 2.235795497894287\n",
      "epoch [1/4], step [12000/12500], loss: 2.2670185565948486\n",
      "epoch [2/4], step [2000/12500], loss: 1.9421439170837402\n",
      "epoch [2/4], step [4000/12500], loss: 1.843127727508545\n",
      "epoch [2/4], step [6000/12500], loss: 2.53489351272583\n",
      "epoch [2/4], step [8000/12500], loss: 1.8630787134170532\n",
      "epoch [2/4], step [10000/12500], loss: 1.503590703010559\n",
      "epoch [2/4], step [12000/12500], loss: 1.8765625953674316\n",
      "epoch [3/4], step [2000/12500], loss: 1.0686606168746948\n",
      "epoch [3/4], step [4000/12500], loss: 1.6661685705184937\n",
      "epoch [3/4], step [6000/12500], loss: 1.9689804315567017\n",
      "epoch [3/4], step [8000/12500], loss: 1.7867835760116577\n",
      "epoch [3/4], step [10000/12500], loss: 2.406804084777832\n",
      "epoch [3/4], step [12000/12500], loss: 1.452519416809082\n",
      "epoch [4/4], step [2000/12500], loss: 1.0834487676620483\n",
      "epoch [4/4], step [4000/12500], loss: 2.338414192199707\n",
      "epoch [4/4], step [6000/12500], loss: 1.2446844577789307\n",
      "epoch [4/4], step [8000/12500], loss: 1.5431127548217773\n",
      "epoch [4/4], step [10000/12500], loss: 1.0550730228424072\n",
      "epoch [4/4], step [12000/12500], loss: 2.8469319343566895\n",
      "training finised\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                            download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                            transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\",\n",
    "          \"ship\", \"truck\")\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5) #flatten\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2000 == 0:\n",
    "            print(f\"epoch [{epoch+1}/{num_epochs}], step [{i+1}/{n_total_steps}], loss: {loss.item()}\")\n",
    "\n",
    "print(\"training finised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd286db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T19:14:22.345659Z",
     "start_time": "2022-12-01T19:14:01.784706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 46.51 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f\"Accuracy of the network: {acc} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327a03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicoding",
   "language": "python",
   "name": "aicoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
